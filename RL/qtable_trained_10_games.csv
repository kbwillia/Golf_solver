state,action,q_value,last_action,debug
"('5', '6', '9', 'J')_0.0_4_4",take_discard_3,1.01,g_r4: Q-learning agent took from discard and placed at position 4,{}
"('2', '6', '6', 'K')_-9.0_10_4",draw_deck_flip_3,1.01,"g_r4: Q-learning agent drew from deck, discarded it, and flipped position 4",{}
"('2', '7', '7', 'J')_-13.0_6_4",take_discard_3,1.01,g_r4: Q-learning agent took from discard and placed at position 4,{}
"('2', '3', '3', '9')_-4.5_A_4",take_discard_3,1.01,g_r4: Q-learning agent took from discard and placed at position 4,{}
"('10', '2', 'Q', 'Q')_1.5_4_4",take_discard_3,1.01,g_r4: Q-learning agent took from discard and placed at position 4,{}
"('2', '3', 'J', 'Q')_11.5_Q_4",take_discard_3,1.01,g_r4: Q-learning agent took from discard and placed at position 4,{}
"('9', 'Q')_-9.0_9_1",take_discard_0,0.010000000000000002,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('9', '9', 'Q')_-19.0_10_2",take_discard_1,0.010000000000000002,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('10', '9', '9', 'Q')_-16.0_7_3",take_discard_2,0.010000000000000002,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('10', '9')_-3.0_3_1",take_discard_0,0.010000000000000002,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('10', '3', '9')_-10.0_Q_2",take_discard_1,0.010000000000000002,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('10', '3', '9', 'Q')_0.0_4_3",take_discard_2,0.010000000000000002,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('8', '9')_-7.5_10_1",take_discard_0,0.010000000000000002,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('10', '8', '9')_-6.5_8_2",take_discard_1,0.010000000000000002,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('10', '8', '8', '9')_0.0_8_3",take_discard_2,0.010000000000000002,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('4', '9')_-4.0_5_1",take_discard_0,0.010000000000000002,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('4', '5', '9')_2.5_J_2",take_discard_1,0.010000000000000002,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('4', '5', '9', 'J')_-3.5_6_3",take_discard_2,0.010000000000000002,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('2', '7')_-4.0_6_1",take_discard_0,0.010000000000000002,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('2', '6', '7')_7.5_6_2",take_discard_1,0.010000000000000002,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('2', '6', '6', '7')_-8.5_K_3",take_discard_2,0.010000000000000002,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('2', '7', 'J')_-3.5_7_3",take_discard_1,0.010000000000000002,g_r3: Q-learning agent took from discard and placed at position 2,{}
"('7', 'J')_-10.0_10_2",draw_deck_0,0.010000000000000002,g_r2: Q-learning agent drew from deck and kept at position 1,{}
"('4', '7')_0.0_J_1",take_discard_2,0.010000000000000002,g_r1: Q-learning agent took from discard and placed at position 3,{}
"('3', '7')_-6.5_9_1",take_discard_0,0.010000000000000002,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('3', '7', '9')_-0.5_2_2",take_discard_1,0.010000000000000002,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('2', '3', '7', '9')_10.5_9_3",draw_deck_2,0.010000000000000002,g_r3: Q-learning agent drew from deck and kept at position 3,{}
"('10', '4')_2.0_A_1",take_discard_0,0.010000000000000002,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('10', '8', 'A')_-5.0_9_3",take_discard_1,0.010000000000000002,g_r3: Q-learning agent took from discard and placed at position 2,{}
"('10', '4', 'A')_-5.0_8_2",take_discard_3,0.010000000000000002,g_r2: Q-learning agent took from discard and placed at position 4,{}
"('10', '4', 'Q')_11.0_Q_2",take_discard_1,0.010000000000000002,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('10', '4', 'Q', 'Q')_1.0_2_3",take_discard_2,0.010000000000000002,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('10', '4')_0.0_2_1",draw_deck_flip_0,0.010000000000000002,"g_r1: Q-learning agent drew from deck, discarded it, and flipped position 1",{}
"('2', '3', 'Q')_1.5_J_3",take_discard_0,0.010000000000000002,g_r3: Q-learning agent took from discard and placed at position 1,{}
"('3', 'Q')_-2.5_2_2",take_discard_1,0.010000000000000002,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('3', '5')_-10.0_Q_1",take_discard_2,0.010000000000000002,g_r1: Q-learning agent took from discard and placed at position 3,{}
"('9', 'Q')_-9.0_9_1",take_discard_1,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('9', 'Q')_-9.0_9_1",take_discard_2,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('9', 'Q')_-9.0_9_1",take_discard_3,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('9', 'Q')_-9.0_9_1",draw_deck_0,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('9', 'Q')_-9.0_9_1",draw_deck_1,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('9', 'Q')_-9.0_9_1",draw_deck_2,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('9', 'Q')_-9.0_9_1",draw_deck_3,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('9', 'Q')_-9.0_9_1",draw_deck_flip_0,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('9', 'Q')_-9.0_9_1",draw_deck_flip_1,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('9', 'Q')_-9.0_9_1",draw_deck_flip_2,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('9', 'Q')_-9.0_9_1",draw_deck_flip_3,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('9', '9', 'Q')_-19.0_10_2",take_discard_2,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('9', '9', 'Q')_-19.0_10_2",take_discard_3,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('9', '9', 'Q')_-19.0_10_2",draw_deck_1,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('9', '9', 'Q')_-19.0_10_2",draw_deck_2,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('9', '9', 'Q')_-19.0_10_2",draw_deck_3,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('9', '9', 'Q')_-19.0_10_2",draw_deck_flip_1,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('9', '9', 'Q')_-19.0_10_2",draw_deck_flip_2,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('9', '9', 'Q')_-19.0_10_2",draw_deck_flip_3,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('10', '9', '9', 'Q')_-16.0_7_3",take_discard_3,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('10', '9', '9', 'Q')_-16.0_7_3",draw_deck_2,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('10', '9', '9', 'Q')_-16.0_7_3",draw_deck_3,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('10', '9', '9', 'Q')_-16.0_7_3",draw_deck_flip_2,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('10', '9', '9', 'Q')_-16.0_7_3",draw_deck_flip_3,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('10', '7', '9', '9')_-17.0_8_4",draw_deck_3,0.0,g_r4: Q-learning agent took from discard and placed at position 4,{}
"('10', '7', '9', '9')_-17.0_8_4",draw_deck_flip_3,0.0,g_r4: Q-learning agent took from discard and placed at position 4,{}
"('10', '9')_-3.0_3_1",take_discard_1,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('10', '9')_-3.0_3_1",take_discard_2,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('10', '9')_-3.0_3_1",take_discard_3,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('10', '9')_-3.0_3_1",draw_deck_0,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('10', '9')_-3.0_3_1",draw_deck_1,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('10', '9')_-3.0_3_1",draw_deck_2,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('10', '9')_-3.0_3_1",draw_deck_3,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('10', '9')_-3.0_3_1",draw_deck_flip_0,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('10', '9')_-3.0_3_1",draw_deck_flip_1,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('10', '9')_-3.0_3_1",draw_deck_flip_2,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('10', '9')_-3.0_3_1",draw_deck_flip_3,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('10', '3', '9')_-10.0_Q_2",take_discard_2,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('10', '3', '9')_-10.0_Q_2",take_discard_3,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('10', '3', '9')_-10.0_Q_2",draw_deck_1,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('10', '3', '9')_-10.0_Q_2",draw_deck_2,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('10', '3', '9')_-10.0_Q_2",draw_deck_3,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('10', '3', '9')_-10.0_Q_2",draw_deck_flip_1,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('10', '3', '9')_-10.0_Q_2",draw_deck_flip_2,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('10', '3', '9')_-10.0_Q_2",draw_deck_flip_3,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('10', '3', '9', 'Q')_0.0_4_3",take_discard_3,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('10', '3', '9', 'Q')_0.0_4_3",draw_deck_2,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('10', '3', '9', 'Q')_0.0_4_3",draw_deck_3,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('10', '3', '9', 'Q')_0.0_4_3",draw_deck_flip_2,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('10', '3', '9', 'Q')_0.0_4_3",draw_deck_flip_3,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('8', '9')_-7.5_10_1",take_discard_1,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('8', '9')_-7.5_10_1",take_discard_2,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('8', '9')_-7.5_10_1",take_discard_3,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('8', '9')_-7.5_10_1",draw_deck_0,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('8', '9')_-7.5_10_1",draw_deck_1,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('8', '9')_-7.5_10_1",draw_deck_2,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('8', '9')_-7.5_10_1",draw_deck_3,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('8', '9')_-7.5_10_1",draw_deck_flip_0,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('8', '9')_-7.5_10_1",draw_deck_flip_1,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('8', '9')_-7.5_10_1",draw_deck_flip_2,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('8', '9')_-7.5_10_1",draw_deck_flip_3,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('10', '8', '9')_-6.5_8_2",take_discard_2,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('10', '8', '9')_-6.5_8_2",take_discard_3,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('10', '8', '9')_-6.5_8_2",draw_deck_1,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('10', '8', '9')_-6.5_8_2",draw_deck_2,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('10', '8', '9')_-6.5_8_2",draw_deck_3,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('10', '8', '9')_-6.5_8_2",draw_deck_flip_1,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('10', '8', '9')_-6.5_8_2",draw_deck_flip_2,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('10', '8', '9')_-6.5_8_2",draw_deck_flip_3,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('10', '8', '8', '9')_0.0_8_3",take_discard_3,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('10', '8', '8', '9')_0.0_8_3",draw_deck_2,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('10', '8', '8', '9')_0.0_8_3",draw_deck_3,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('10', '8', '8', '9')_0.0_8_3",draw_deck_flip_2,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('10', '8', '8', '9')_0.0_8_3",draw_deck_flip_3,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('10', '8', '8', '9')_3.0_A_4",draw_deck_3,0.0,g_r4: Q-learning agent took from discard and placed at position 4,{}
"('10', '8', '8', '9')_3.0_A_4",draw_deck_flip_3,0.0,g_r4: Q-learning agent took from discard and placed at position 4,{}
"('4', '9')_-4.0_5_1",take_discard_1,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('4', '9')_-4.0_5_1",take_discard_2,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('4', '9')_-4.0_5_1",take_discard_3,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('4', '9')_-4.0_5_1",draw_deck_0,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('4', '9')_-4.0_5_1",draw_deck_1,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('4', '9')_-4.0_5_1",draw_deck_2,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('4', '9')_-4.0_5_1",draw_deck_3,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('4', '9')_-4.0_5_1",draw_deck_flip_0,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('4', '9')_-4.0_5_1",draw_deck_flip_1,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('4', '9')_-4.0_5_1",draw_deck_flip_2,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('4', '9')_-4.0_5_1",draw_deck_flip_3,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('4', '5', '9')_2.5_J_2",take_discard_2,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('4', '5', '9')_2.5_J_2",take_discard_3,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('4', '5', '9')_2.5_J_2",draw_deck_1,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('4', '5', '9')_2.5_J_2",draw_deck_2,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('4', '5', '9')_2.5_J_2",draw_deck_3,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('4', '5', '9')_2.5_J_2",draw_deck_flip_1,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('4', '5', '9')_2.5_J_2",draw_deck_flip_2,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('4', '5', '9')_2.5_J_2",draw_deck_flip_3,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('4', '5', '9', 'J')_-3.5_6_3",take_discard_3,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('4', '5', '9', 'J')_-3.5_6_3",draw_deck_2,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('4', '5', '9', 'J')_-3.5_6_3",draw_deck_3,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('4', '5', '9', 'J')_-3.5_6_3",draw_deck_flip_2,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('4', '5', '9', 'J')_-3.5_6_3",draw_deck_flip_3,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('5', '6', '9', 'J')_0.0_4_4",draw_deck_3,0.0,g_r4: Q-learning agent took from discard and placed at position 4,{}
"('5', '6', '9', 'J')_0.0_4_4",draw_deck_flip_3,0.0,g_r4: Q-learning agent took from discard and placed at position 4,{}
"('2', '7')_-4.0_6_1",take_discard_1,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('2', '7')_-4.0_6_1",take_discard_2,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('2', '7')_-4.0_6_1",take_discard_3,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('2', '7')_-4.0_6_1",draw_deck_0,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('2', '7')_-4.0_6_1",draw_deck_1,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('2', '7')_-4.0_6_1",draw_deck_2,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('2', '7')_-4.0_6_1",draw_deck_3,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('2', '7')_-4.0_6_1",draw_deck_flip_0,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('2', '7')_-4.0_6_1",draw_deck_flip_1,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('2', '7')_-4.0_6_1",draw_deck_flip_2,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('2', '7')_-4.0_6_1",draw_deck_flip_3,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('2', '6', '7')_7.5_6_2",take_discard_2,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('2', '6', '7')_7.5_6_2",take_discard_3,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('2', '6', '7')_7.5_6_2",draw_deck_1,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('2', '6', '7')_7.5_6_2",draw_deck_2,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('2', '6', '7')_7.5_6_2",draw_deck_3,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('2', '6', '7')_7.5_6_2",draw_deck_flip_1,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('2', '6', '7')_7.5_6_2",draw_deck_flip_2,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('2', '6', '7')_7.5_6_2",draw_deck_flip_3,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('2', '6', '6', '7')_-8.5_K_3",take_discard_3,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('2', '6', '6', '7')_-8.5_K_3",draw_deck_2,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('2', '6', '6', '7')_-8.5_K_3",draw_deck_3,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('2', '6', '6', '7')_-8.5_K_3",draw_deck_flip_2,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('2', '6', '6', '7')_-8.5_K_3",draw_deck_flip_3,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('2', '7', 'J')_-3.5_7_3",take_discard_3,0.0,g_r3: Q-learning agent took from discard and placed at position 2,{}
"('2', '7', 'J')_-3.5_7_3",draw_deck_1,0.0,g_r3: Q-learning agent took from discard and placed at position 2,{}
"('2', '7', 'J')_-3.5_7_3",draw_deck_3,0.0,g_r3: Q-learning agent took from discard and placed at position 2,{}
"('2', '7', 'J')_-3.5_7_3",draw_deck_flip_1,0.0,g_r3: Q-learning agent took from discard and placed at position 2,{}
"('2', '7', 'J')_-3.5_7_3",draw_deck_flip_3,0.0,g_r3: Q-learning agent took from discard and placed at position 2,{}
"('2', '7', '7', 'J')_-13.0_6_4",draw_deck_3,0.0,g_r4: Q-learning agent took from discard and placed at position 4,{}
"('2', '7', '7', 'J')_-13.0_6_4",draw_deck_flip_3,0.0,g_r4: Q-learning agent took from discard and placed at position 4,{}
"('3', '7')_-6.5_9_1",take_discard_1,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('3', '7')_-6.5_9_1",take_discard_2,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('3', '7')_-6.5_9_1",take_discard_3,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('3', '7')_-6.5_9_1",draw_deck_0,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('3', '7')_-6.5_9_1",draw_deck_1,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('3', '7')_-6.5_9_1",draw_deck_2,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('3', '7')_-6.5_9_1",draw_deck_3,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('3', '7')_-6.5_9_1",draw_deck_flip_0,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('3', '7')_-6.5_9_1",draw_deck_flip_1,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('3', '7')_-6.5_9_1",draw_deck_flip_2,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('3', '7')_-6.5_9_1",draw_deck_flip_3,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('3', '7', '9')_-0.5_2_2",take_discard_2,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('3', '7', '9')_-0.5_2_2",take_discard_3,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('3', '7', '9')_-0.5_2_2",draw_deck_1,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('3', '7', '9')_-0.5_2_2",draw_deck_2,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('3', '7', '9')_-0.5_2_2",draw_deck_3,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('3', '7', '9')_-0.5_2_2",draw_deck_flip_1,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('3', '7', '9')_-0.5_2_2",draw_deck_flip_2,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('3', '7', '9')_-0.5_2_2",draw_deck_flip_3,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('2', '3', '3', '9')_-4.5_A_4",draw_deck_3,0.0,g_r4: Q-learning agent took from discard and placed at position 4,{}
"('2', '3', '3', '9')_-4.5_A_4",draw_deck_flip_3,0.0,g_r4: Q-learning agent took from discard and placed at position 4,{}
"('10', '4')_2.0_A_1",take_discard_1,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('10', '4')_2.0_A_1",take_discard_2,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('10', '4')_2.0_A_1",take_discard_3,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('10', '4')_2.0_A_1",draw_deck_0,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('10', '4')_2.0_A_1",draw_deck_1,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('10', '4')_2.0_A_1",draw_deck_2,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('10', '4')_2.0_A_1",draw_deck_3,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('10', '4')_2.0_A_1",draw_deck_flip_0,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('10', '4')_2.0_A_1",draw_deck_flip_1,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('10', '4')_2.0_A_1",draw_deck_flip_2,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('10', '4')_2.0_A_1",draw_deck_flip_3,0.0,g_r1: Q-learning agent took from discard and placed at position 1,{}
"('10', '8', 'A')_-5.0_9_3",take_discard_2,0.0,g_r3: Q-learning agent took from discard and placed at position 2,{}
"('10', '8', 'A')_-5.0_9_3",draw_deck_1,0.0,g_r3: Q-learning agent took from discard and placed at position 2,{}
"('10', '8', 'A')_-5.0_9_3",draw_deck_2,0.0,g_r3: Q-learning agent took from discard and placed at position 2,{}
"('10', '8', 'A')_-5.0_9_3",draw_deck_flip_1,0.0,g_r3: Q-learning agent took from discard and placed at position 2,{}
"('10', '8', 'A')_-5.0_9_3",draw_deck_flip_2,0.0,g_r3: Q-learning agent took from discard and placed at position 2,{}
"('10', '8', '9', 'A')_-1.5_5_4",draw_deck_2,0.0,g_r4: Q-learning agent took from discard and placed at position 3,{}
"('10', '8', '9', 'A')_-1.5_5_4",draw_deck_flip_2,0.0,g_r4: Q-learning agent took from discard and placed at position 3,{}
"('10', '4', 'Q')_11.0_Q_2",take_discard_2,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('10', '4', 'Q')_11.0_Q_2",take_discard_3,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('10', '4', 'Q')_11.0_Q_2",draw_deck_1,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('10', '4', 'Q')_11.0_Q_2",draw_deck_2,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('10', '4', 'Q')_11.0_Q_2",draw_deck_3,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('10', '4', 'Q')_11.0_Q_2",draw_deck_flip_1,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('10', '4', 'Q')_11.0_Q_2",draw_deck_flip_2,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('10', '4', 'Q')_11.0_Q_2",draw_deck_flip_3,0.0,g_r2: Q-learning agent took from discard and placed at position 2,{}
"('10', '4', 'Q', 'Q')_1.0_2_3",take_discard_3,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('10', '4', 'Q', 'Q')_1.0_2_3",draw_deck_2,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('10', '4', 'Q', 'Q')_1.0_2_3",draw_deck_3,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('10', '4', 'Q', 'Q')_1.0_2_3",draw_deck_flip_2,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('10', '4', 'Q', 'Q')_1.0_2_3",draw_deck_flip_3,0.0,g_r3: Q-learning agent took from discard and placed at position 3,{}
"('2', '3', 'Q')_1.5_J_3",take_discard_3,0.0,g_r3: Q-learning agent took from discard and placed at position 1,{}
"('2', '3', 'Q')_1.5_J_3",draw_deck_0,0.0,g_r3: Q-learning agent took from discard and placed at position 1,{}
"('2', '3', 'Q')_1.5_J_3",draw_deck_3,0.0,g_r3: Q-learning agent took from discard and placed at position 1,{}
"('2', '3', 'Q')_1.5_J_3",draw_deck_flip_0,0.0,g_r3: Q-learning agent took from discard and placed at position 1,{}
"('2', '3', 'Q')_1.5_J_3",draw_deck_flip_3,0.0,g_r3: Q-learning agent took from discard and placed at position 1,{}
"('10', '8', '8', '9')_3.0_A_4",take_discard_3,-0.19,g_r4: Q-learning agent took from discard and placed at position 4,{}
"('10', '7', '9', '9')_-17.0_8_4",take_discard_3,-0.49000000000000005,g_r4: Q-learning agent took from discard and placed at position 4,{}
"('3', '4', '9', 'Q')_-2.5_6_4",draw_deck_flip_3,-0.49000000000000005,"g_r4: Q-learning agent drew from deck, discarded it, and flipped position 4",{}
"('10', '8', '9', 'A')_-1.5_5_4",take_discard_2,-0.49000000000000005,g_r4: Q-learning agent took from discard and placed at position 3,{}
